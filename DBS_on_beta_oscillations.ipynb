{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3841bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from finn.basic import downsampling, common_average_rereferncing\n",
    "from finn.cleansing import bad_channel_identification\n",
    "import pickle\n",
    "from pylab import *\n",
    "from scipy.integrate import simps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_0(x, fs):\n",
    "    b, a = signal.butter(N=4, Wn=300, btype='lowpass', fs=fs)\n",
    "    z = signal.lfilter(b, a, x)\n",
    "    return z\n",
    "\n",
    "def bandpass(x, freq):\n",
    "    b, a = signal.butter(N=4, Wn=[0.53,50], btype='bandpass', fs=freq)\n",
    "    z = signal.lfilter(b, a, x)\n",
    "    return z\n",
    "\n",
    "def notch(x, freq):\n",
    "        b, a = signal.iirnotch(50, 50/5, fs=freq)\n",
    "        z = signal.lfilter(b, a, x)\n",
    "        return z\n",
    "\n",
    "def epoch(data, t1, t2, fs, t_int, num_ch):\n",
    "    d1 = t1 * fs\n",
    "    d2 = t2 * fs\n",
    "    data = data[:,d1:d2]\n",
    "    d3 = t_int * fs\n",
    "    num_epoch = int((t2 - t1)/t_int) \n",
    "    epoch_data = [[0]] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        epoch_data[i] = [data[i,0: d3]]\n",
    "        for j in range(d3, len(data[i]), d3):\n",
    "            epoch_data[i].append(data[i,j:j + d3])\n",
    "    epoch_data = np.array(epoch_data)\n",
    "    epoch_data = np.transpose(epoch_data, (1,0,2))\n",
    "    return epoch_data\n",
    "\n",
    "def epoch_extract_beta(data, fs):\n",
    "    epoch_power = np.zeros([len(data),len(data[0])])\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            power = signal.welch(data[i][j], fs, nfft = fs, nperseg = fs)[1]\n",
    "            epoch_power[i,j] = np.sum(power[13:32])/np.sum(power[0:300])\n",
    "    return epoch_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1863804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_file(path, path_info, fs, freq):\n",
    "    with open(path, 'rb') as file:\n",
    "        data = np.load(file)\n",
    "        data = data['arr_0']\n",
    "\n",
    "    run_00_hdr = open(path_info, 'rb')\n",
    "    model_input = pickle.load(run_00_hdr)\n",
    "    ch_names = model_input['chNames']\n",
    "\n",
    "    ## Step 0: Lowpass filter before downsample\n",
    "    step0 = np.apply_along_axis(step_0, 1, data, fs)\n",
    "\n",
    "    ## Step 1: Downsample\n",
    "    func = lambda x: downsampling.run(x, src_freq=fs, tgt_freq=freq)\n",
    "    step1 = np.apply_along_axis(func, 1, step0)\n",
    "    \n",
    "    \n",
    "    ## Step 1b: Remove Bad Channels \n",
    "    try:\n",
    "        x = bad_channel_identification.run(\n",
    "        step1,\n",
    "        ch_names=ch_names,\n",
    "        fs=[freq]*len(step1),\n",
    "        ref_areas=[[60,100]],\n",
    "        broadness=3,\n",
    "        visual_inspection=False\n",
    "        )\n",
    "        ch_names = [ch_names[i] for i in x[0]]\n",
    "        step1b = [step1[i] for i in x[0]]\n",
    "        if step1b != []:\n",
    "            step1 = step1b\n",
    "    except:\n",
    "        print(\"Bad channel identification failed\")\n",
    "    \n",
    "    num_ch = len(ch_names)\n",
    "    \n",
    "\n",
    "    ## Step 2: Bandpass filter (0.53 - 50 Hz)\n",
    "\n",
    "    step2 = np.apply_along_axis(bandpass, 1, step1, freq)\n",
    "\n",
    "    ## Step 3: Notch filter at 50 Hz\n",
    "\n",
    "    step3 = np.apply_along_axis(notch, 1, step2, freq)\n",
    "\n",
    "    ## Step 4: common avg re-ref\n",
    "\n",
    "    step4 = common_average_rereferncing.run(step3)\n",
    "\n",
    "    ## Step 5: Epoch and Split Data\n",
    "\n",
    "    step5a = epoch(step4, 4, 26, freq, 2, num_ch)\n",
    "    step5b = epoch(step4, 54, 76,freq, 2, num_ch)\n",
    "\n",
    "    # Step 6: Extract power in the beta-frequency band and normalize by power between 0 and 300Hz\n",
    "\n",
    "    step6a = epoch_extract_beta(step5a, freq)\n",
    "    step6b = epoch_extract_beta(step5b, freq)\n",
    "\n",
    "    return step6a, step6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5615d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "fs = 5000\n",
    "freq = 600\n",
    "\n",
    "rootdir = r'C:\\Users\\laurawheeler\\Desktop\\beta'\n",
    "destdir = r'C:\\Users\\laurawheeler\\Desktop\\beta_processed'\n",
    "\n",
    "path_run = 'hi'\n",
    "path_info_run = 'hello'\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in tqdm(files):\n",
    "        filepath = subdir + os.sep + file\n",
    "\n",
    "        if filepath.endswith(\".npz\"):\n",
    "            path = filepath\n",
    "            path_run = path[path.index('run'):]\n",
    "            path_run = path_run[:6]\n",
    "\n",
    "        if filepath.endswith(\".pkl\"):\n",
    "            path_info = filepath\n",
    "            path_info_run = path_info[path_info.index('run'):]\n",
    "            path_info_run = path_run[:6]\n",
    "        \n",
    "        if path_run == path_info_run:\n",
    "            try:\n",
    "                data1, data2 = single_file(path, path_info, fs, freq)\n",
    "                path = path[path.index('beta')+4:-8]\n",
    "                path_a = destdir + path + \"_a.csv\"\n",
    "                np.savetxt(path_a, data1, delimiter=\",\")\n",
    "                path_b = destdir + path + \"_b.csv\"\n",
    "                np.savetxt(path_b, data2, delimiter=\",\")\n",
    "            except:\n",
    "                print(path, \"Encountered an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e4ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get channel names in order from each trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import signal\n",
    "from finn.basic import downsampling, common_average_rereferncing\n",
    "from finn.cleansing import bad_channel_identification\n",
    "import pickle\n",
    "from pylab import *\n",
    "from scipy.integrate import simps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_0(x, fs):\n",
    "    b, a = signal.butter(N=4, Wn=300, btype='lowpass', fs=fs)\n",
    "    z = signal.lfilter(b, a, x)\n",
    "    return z\n",
    "\n",
    "def bandpass(x, freq):\n",
    "    b, a = signal.butter(N=4, Wn=[0.53,50], btype='bandpass', fs=freq)\n",
    "    z = signal.lfilter(b, a, x)\n",
    "    return z\n",
    "\n",
    "def notch(x, freq):\n",
    "        b, a = signal.iirnotch(50, 50/5, fs=freq)\n",
    "        z = signal.lfilter(b, a, x)\n",
    "        return z\n",
    "\n",
    "def epoch(data, t1, t2, fs, t_int):\n",
    "    d1 = t1 * fs\n",
    "    d2 = t2 * fs\n",
    "    data = data[:,d1:d2]\n",
    "    d3 = t_int * fs\n",
    "    num_epoch = int((t2 - t1)/t_int) \n",
    "    epoch_data = [[0]] * len(data)\n",
    "    for i in range(len(data)):\n",
    "        epoch_data[i] = [data[i,0: d3]]\n",
    "        for j in range(d3, len(data[i]), d3):\n",
    "            epoch_data[i].append(data[i,j:j + d3])\n",
    "    epoch_data = np.array(epoch_data)\n",
    "    epoch_data = np.transpose(epoch_data, (1,0,2))\n",
    "    return epoch_data\n",
    "\n",
    "def epoch_extract_beta(data, fs):\n",
    "    epoch_power = np.zeros([len(data),len(data[0])])\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            power = signal.welch(data[i][j], fs, nfft = fs, nperseg = fs)[1]\n",
    "            epoch_power[i,j] = np.sum(power[13:32])/np.sum(power[0:300])\n",
    "    return epoch_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcaea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_file(path, path_info, fs, freq):\n",
    "    with open(path, 'rb') as file:\n",
    "        data = np.load(file)\n",
    "        data = data['arr_0']\n",
    "\n",
    "    run_00_hdr = open(path_info, 'rb')\n",
    "    model_input = pickle.load(run_00_hdr)\n",
    "    ch_names = model_input['chNames']\n",
    "\n",
    "    ## Step 0: Lowpass filter before downsample\n",
    "    step0 = np.apply_along_axis(step_0, 1, data, fs)\n",
    "\n",
    "    ## Step 1: Downsample\n",
    "    func = lambda x: downsampling.run(x, src_freq=fs, tgt_freq=freq)\n",
    "    step1 = np.apply_along_axis(func, 1, step0)\n",
    "    \n",
    "    \n",
    "    ## Step 1b: Remove Bad Channels \n",
    "    try:\n",
    "        x = bad_channel_identification.run(\n",
    "        step1,\n",
    "        ch_names=ch_names,\n",
    "        fs=[freq]*len(step1),\n",
    "        ref_areas=[[60,100]],\n",
    "        broadness=3,\n",
    "        visual_inspection=False\n",
    "        )\n",
    "        ch_names = [ch_names[i] for i in x[0]]\n",
    "        step1b = [step1[i] for i in x[0]]\n",
    "        if step1b != []:\n",
    "            step1 = step1b\n",
    "        else:\n",
    "            ch_names = model_input['chNames']\n",
    "    except:\n",
    "        print(\"Bad channel identification failed\")\n",
    "\n",
    "    return ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f428665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "fs = 5000\n",
    "freq = 600\n",
    "\n",
    "rootdir = r'C:\\Users\\laurawheeler\\Desktop\\beta'\n",
    "destdir = r'C:\\Users\\laurawheeler\\Desktop\\beta_processed'\n",
    "\n",
    "path_run = 'hi'\n",
    "path_info_run = 'hello'\n",
    "\n",
    "file_channels = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in tqdm(files):\n",
    "        filepath = subdir + os.sep + file\n",
    "\n",
    "        if filepath.endswith(\".npz\"):\n",
    "            path = filepath\n",
    "            path_run = path[path.index('run'):]\n",
    "            path_run = path_run[:6]\n",
    "\n",
    "        if filepath.endswith(\".pkl\"):\n",
    "            path_info = filepath\n",
    "            path_info_run = path_info[path_info.index('run'):]\n",
    "            path_info_run = path_run[:6]\n",
    "        \n",
    "        if path_run == path_info_run:\n",
    "            try:\n",
    "                ch_names = single_file(path, path_info, fs, freq)\n",
    "                path = path[path.index('beta')+4:-8]\n",
    "                path_a = destdir + path + \"_a.csv\"\n",
    "                file_channels.append([path_a[41:],ch_names])\n",
    "                path_b = destdir + path + \"_b.csv\"\n",
    "                file_channels.append([path_b[41:],ch_names])\n",
    "            except:\n",
    "                print(path, \"Encountered an error\")\n",
    "\n",
    "with open(r'C:\\Users\\laurawheeler\\Desktop\\ch_names.ob', 'wb') as fp:\n",
    "    pickle.dump(file_channels,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c469a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ANOVA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1a0b7c-1641-4ebc-a8ce-7f5505321204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "import os\n",
    "BASE_PATH = r'C:\\Users\\laurawheeler\\Downloads\\ANOVA\\ANOVA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec40e0a-416a-48c4-aca6-da1973ae0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chNames = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', \n",
    "            'T7', 'C3', 'Cz', 'C4', 'T8', 'TP9', 'CP5', 'CP1', 'CP2', 'CP6', 'TP10', \n",
    "            'P7', 'P3', 'Pz', 'P4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'AF7', 'AF3', \n",
    "            'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FT9', 'FT7', 'FC3', 'FC4', 'FT8', 'FT10', \n",
    "            'C5', 'C1', 'C2', 'C6', 'TP7', 'CP3', 'CPz', 'CP4', 'TP8', 'P5', 'P1', 'P2', 'P6', \n",
    "            'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'LT']\n",
    "\n",
    "all_p_vals = []\n",
    "\n",
    "for col_name in chNames:\n",
    "\n",
    "    df_all = pd.DataFrame([])\n",
    "    for i in os.listdir(f\"{BASE_PATH}/beta_processed\"):  # for each participant\n",
    "        if not i.isdigit():\n",
    "            continue\n",
    "        \n",
    "        path = f\"{BASE_PATH}/beta_processed/{i}/raw/D1/left_r/\"\n",
    "        for file in os.listdir(path):  # for each participant \"run\"\n",
    "\n",
    "            metadata_path = f\"{BASE_PATH}/pickles/{i}/raw/D1/left_r/{file[:-10]}hdr.pkl\"\n",
    "            metadata = pickle.load(open(metadata_path, 'rb'))\n",
    "\n",
    "            # get the index of the channel name we're interested in\n",
    "            index = metadata['chNames'].index(col_name)\n",
    "            if index == -1:\n",
    "                print(f\"skipping {file} due to missing column\")\n",
    "                continue\n",
    "            \n",
    "            # load the data for the channel we want\n",
    "            data = np.loadtxt(open(path + file, \"rb\"), delimiter=\",\")[:,index]\n",
    "            \n",
    "            # build the dataframe for this run\n",
    "            df = pd.DataFrame(data, columns=[col_name])\n",
    "            df['power'] = df[col_name]\n",
    "            df['stim'] = metadata['stimInt']\n",
    "            df['clin_score'] = metadata['clinScore']\n",
    "            df['patient_id'] = metadata['patientId']\n",
    "            df['move'] = 0 if 'a.csv' in file else 1\n",
    "            df['samp_id'] = np.arange(1, len(df) + 1)\n",
    "            df['file_id'] = 1\n",
    "            df_all = pd.DataFrame.append(df_all, df)\n",
    "\n",
    "    # Apply the 3 way ANOVA\n",
    "    model = ols(\n",
    "        'power ~ C(move) + C(stim) + C(clin_score) + C(move):C(stim) + C(clin_score):C(stim)'\\\n",
    "        '+ C(move):C(clin_score) + (1|patient_id) + (1|file_id) + (1|samp_id)',\n",
    "        data=df_all\n",
    "    ).fit()\n",
    "\n",
    "    table = sm.stats.anova_lm(model, typ=3)\n",
    "    table = table[1:7]\n",
    "    p_vals = table['PR(>F)']\n",
    "    p_vals = p_vals.to_list()\n",
    "    all_p_vals.append(p_vals)\n",
    " \n",
    "\n",
    "with open(r'C:\\Users\\laurawheeler\\Desktop\\pppppp.ob', 'wb') as fp:\n",
    "    pickle.dump(all_p_vals,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167fc153-5c34-4a00-9718-bd6afc0a222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the Dataframe for JMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all participant data for all electrodes into one dataframe to use in JMP\n",
    "\n",
    "chNames = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', \n",
    "            'T7', 'C3', 'Cz', 'C4', 'T8', 'TP9', 'CP5', 'CP1', 'CP2', 'CP6', 'TP10', \n",
    "            'P7', 'P3', 'Pz', 'P4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'AF7', 'AF3', \n",
    "            'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FT9', 'FT7', 'FC3', 'FC4', 'FT8', 'FT10', \n",
    "            'C5', 'C1', 'C2', 'C6', 'TP7', 'CP3', 'CPz', 'CP4', 'TP8', 'P5', 'P1', 'P2', 'P6', \n",
    "            'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'LT']\n",
    "\n",
    "df_all_all = pd.DataFrame([])\n",
    "for col_name in tqdm(chNames):\n",
    "    df_all = pd.DataFrame([])\n",
    "    for i in os.listdir(f\"{BASE_PATH}/beta_processed\"):  # for each participant\n",
    "        if not i.isdigit():\n",
    "            continue\n",
    "\n",
    "        path = f\"{BASE_PATH}/beta_processed/{i}/raw/D1/left_r/\"\n",
    "        for file in os.listdir(path):  # for each participant \"run\"\n",
    "\n",
    "            metadata_path = f\"{BASE_PATH}/pickles/{i}/raw/D1/left_r/{file[:-10]}hdr.pkl\"\n",
    "            metadata = pickle.load(open(metadata_path, 'rb'))\n",
    "\n",
    "            # get the index of the channel name we're interested in\n",
    "            index = metadata['chNames'].index(col_name)\n",
    "            if index == -1:\n",
    "                print(f\"skipping {file} due to missing column\")\n",
    "                continue\n",
    "\n",
    "            # load the data for the channel we want\n",
    "            data = np.loadtxt(open(path + file, \"rb\"), delimiter=\",\")[:,index]\n",
    "\n",
    "            # build the dataframe for this run\n",
    "            df = pd.DataFrame(data, columns=['power'])\n",
    "            df['stim'] = metadata['stimInt']\n",
    "            df['clin_score'] = metadata['clinScore']\n",
    "            df['patient_id'] = metadata['patientId']\n",
    "            df['move'] = 0 if 'a.csv' in file else 1\n",
    "            df['samp_id'] = np.arange(1, len(df) + 1)\n",
    "            df['file_id'] = 1\n",
    "            df_all = pd.DataFrame.append(df_all, df)\n",
    "\n",
    "    df_all_all = pd.DataFrame.append(df_all_all, df_all)\n",
    "df_all_all.to_csv(\"output_updated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73988650",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Average beta power in each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595ca16a-3968-4d42-9776-d0195692b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['power'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Topoplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08d262a2-210e-4c04-a5dd-ff53550568b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import random\n",
    "import pickle\n",
    "import finn.visualization.topoplot as tp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Qt5agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats import multitest\n",
    "\n",
    "\n",
    "with open (r'C:\\Users\\laurawheeler\\Desktop\\pppppp.ob', 'rb') as fp:\n",
    "    p_vals = pickle.load(fp)\n",
    "\n",
    "chNames = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', \n",
    "            'T7', 'C3', 'Cz', 'C4', 'T8', 'TP9', 'CP5', 'CP1', 'CP2', 'CP6', 'TP10', \n",
    "            'P7', 'P3', 'Pz', 'P4', 'P8', 'PO9', 'O1', 'Oz', 'O2', 'PO10', 'AF7', 'AF3', \n",
    "            'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FT9', 'FT7', 'FC3', 'FC4', 'FT8', 'FT10', \n",
    "            'C5', 'C1', 'C2', 'C6', 'TP7', 'CP3', 'CPz', 'CP4', 'TP8', 'P5', 'P1', 'P2', 'P6', \n",
    "            'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'LT']\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(p_vals)\n",
    "\n",
    "headings = ['move','stim', 'clin_score', 'move:stim', 'clin_score:stim', 'move:clin_score']\n",
    "\n",
    "df = pd.DataFrame(p_vals, index = chNames, columns = headings)\n",
    "\n",
    "#df.to_csv(r'C:\\Users\\laurawheeler\\Desktop\\df.csv', encoding='utf-8', index=True)\n",
    "    \n",
    "p_vals = df.sort_index().values.tolist()\n",
    "\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "#df.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_p_vals = []\n",
    "\n",
    "for j in range(len(p_vals)):\n",
    "    sig = []\n",
    "    for v in p_vals[j]:\n",
    "        if v < 0.01:\n",
    "            sig.append(1)\n",
    "        else:\n",
    "            sig.append(0)\n",
    "    sig_p_vals.append(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41217e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_sig = []\n",
    "\n",
    "for i in range(6):\n",
    "    reject, pvals_corrected, _, _ = multitest.multipletests(np.array(p_vals)[:,i], alpha=0.01, method='hs')\n",
    "    corr_sig.append(reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\laurawheeler\\Desktop\\channel_power.csv'\n",
    "df = pd.read_csv(path)\n",
    "chNames = df['Channel'].tolist()\n",
    "pow = df['Power'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86de55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = tp.topoplot(\"EEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(6):\n",
    "    sig_lst = []\n",
    "    for p_ch in sig_p_vals:\n",
    "        sig_lst.append(p_ch[j]) \n",
    "    #print(j)\n",
    "    topo.run(np.asarray([pow, sig_lst, corr_sig[j]]).transpose(), chNames, omit_channels=['RT'], substitute_channels=[{\"src\":[\"Fp1\"], \"tgt\" : \"Fp1\"}], v_min=0, v_max=0.2, v_border_values=[0,0.04,0.08,0.12,0.16], \n",
    "                v_border_labels=['', '0.02', '0.06', '0.10','0.14', '0.18'], file_path=r'C:\\Users\\laurawheeler\\Desktop\\topoplot' + str(j) + '.png', screen_channels=True, annotate_ch_names=True)\n",
    "plt.show(block = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b79033",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Raw Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from pylab import *\n",
    "\n",
    "matplotlib.use(\"Qt5agg\")\n",
    "\n",
    "path = r'C:\\Users\\laurawheeler\\Desktop\\beta\\2\\raw\\D1\\left_r\\run_02_data.npy.npz'\n",
    "with open(path, 'rb') as file:\n",
    "    data = np.load(file)\n",
    "    data = data['arr_0']\n",
    "freq = 5000\n",
    "\n",
    "path_info = r'C:\\Users\\laurawheeler\\Desktop\\beta\\2\\raw\\D1\\left_r\\run_02_hdr.pkl'\n",
    "run_00_hdr = open(path_info, 'rb')\n",
    "model_input = pickle.load(run_00_hdr)\n",
    "ch_names = model_input['chNames']\n",
    "\n",
    "info = mne.create_info(ch_names, 5000)\n",
    "raw_data = mne.io.RawArray(data, info)\n",
    "fig = mne.viz.plot_raw(raw_data)\n",
    "plt.show(block = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463a971-440b-4d52-9717-dbd0025702ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frequency Spectrum Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f46db0-e3af-47e4-a84b-5acfa30791d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'single_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d6d078000f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwelch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m140\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'single_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot Frequency Spectrum of a single trial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = r'/Users/laurawheeler/Desktop/test_data/run_07_data.npy.npz' #choose individual file .npz\n",
    "path_info = r'/Users/laurawheeler/Desktop/test_data/run_07_hdr.pkl' #choose individual file .pkl\n",
    "fs = 5000\n",
    "freq = 600\n",
    "\n",
    "data1, data2, step4 = single_file(path, path_info, fs, freq)\n",
    "\n",
    "freqs, psd = signal.welch(step4[0], fs=freq, nperseg=4*140)\n",
    "plt.figure()\n",
    "plt.semilogy(freqs, psd)\n",
    "\n",
    "#highlight beta band\n",
    "z = np.array([False] * len(freqs))\n",
    "print(freqs.shape)\n",
    "z[int((0.045)*len(freqs)):int((0.112)*len(freqs))] = True\n",
    "plt.fill_between(freqs, psd, color='blue', alpha=0.3, where=z)\n",
    "\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.xlim([0, 60]) \n",
    "plt.ylim([1e-14, 1e-10]) \n",
    "plt.ylabel('Linear spectrum [dB]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d4106-ed28-4ef0-a9a9-bd394ed86823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
